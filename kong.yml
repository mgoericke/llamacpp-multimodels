_format_version: "3.0"

upstreams:
  - name: llama-chat-upstream
    algorithm: round-robin
    healthchecks:
      active:
        healthy:
          interval: 10
          successes: 2
        unhealthy:
          interval: 5
          http_failures: 3
          timeouts: 3
        http_path: /health
        timeout: 5
      passive:
        healthy:
          successes: 3
        unhealthy:
          http_failures: 3
          timeouts: 3
    targets:
      - target: host.docker.internal:8033  # Funktioniert mit extra_hosts
        weight: 100

  - name: llama-embeddings-upstream
    algorithm: round-robin
    healthchecks:
      active:
        healthy:
          interval: 10
          successes: 2
        unhealthy:
          interval: 5
          http_failures: 3
          timeouts: 3
        http_path: /health
        timeout: 5
      passive:
        healthy:
          successes: 3
        unhealthy:
          http_failures: 3
          timeouts: 3
    targets:
      - target: host.docker.internal:8034
        weight: 100

services:
  - name: llama-chat-service
    url: http://llama-chat-upstream
    connect_timeout: 60000
    write_timeout: 60000
    read_timeout: 60000
    
  - name: llama-embeddings-service
    url: http://llama-embeddings-upstream
    connect_timeout: 60000
    write_timeout: 60000
    read_timeout: 60000

routes:
  - name: chat-route
    service: llama-chat-service
    paths:
      - /v1/chat/completions
      - /v1/completions
    strip_path: false
    
  - name: embeddings-route
    service: llama-embeddings-service
    paths:
      - /v1/embeddings
    strip_path: false

plugins:
  - name: key-auth
    enabled: false
    config:
      key_names:
        - apikey
        - x-api-key

consumers:
  - username: client1
    keyauth_credentials:
      - key: dein-sicherer-api-key
